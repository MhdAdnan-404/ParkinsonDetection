{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f646778-2e0d-40d8-8dc7-9c5340fdff31",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "\n",
    "import os  # [DET]\n",
    "os.environ.setdefault(\"CUBLAS_WORKSPACE_CONFIG\", \":16:8\")  # [DET]\n",
    "\n",
    "import re\n",
    "from pathlib import Path\n",
    "from collections import Counter, defaultdict\n",
    "from typing import List, Tuple, Dict, Optional\n",
    "\n",
    "import numpy as np\n",
    "import random\n",
    "import hashlib  # [DET]\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", message=\".*gpu_hist.*deprecated.*\", category=UserWarning)\n",
    "warnings.filterwarnings(\"ignore\", message='.*Parameters: { \"predictor\" } are not used.*', category=UserWarning)\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from torchvision.transforms import InterpolationMode\n",
    "from torchvision.models import resnet18, ResNet18_Weights\n",
    "from PIL import Image\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "import timm\n",
    "\n",
    "# =========================\n",
    "# Config\n",
    "# =========================\n",
    "DATA_ROOT = Path(r\"DATA/PD_Detection_NewHandPD_Dataset\")\n",
    "OUTDIR    = Path(\"checkpoints_img5cv_per_draw_tiles_WINS\")\n",
    "\n",
    "DRAW_TYPES = [\"circle\", \"meander\", \"spiral\"]\n",
    "\n",
    "# Keep circle/spiral as they were; update only meander:\n",
    "EPOCHS_FN    = {\"circle\": 5,       \"meander\": 8,        \"spiral\": 3}\n",
    "LR_INIT      = {\"circle\": 3.16e-4, \"meander\": 3.16e-4,  \"spiral\": 1e-4}\n",
    "BATCH_SIZE   = {\"circle\": 64,      \"meander\": 16,       \"spiral\": 8}\n",
    "LS_EPS       = {\"circle\": 0.05,    \"meander\": 0.0,      \"spiral\": 0.05}\n",
    "WEIGHT_DECAY = {\"circle\": 1e-4,    \"meander\": 0.0,      \"spiral\": 0.0}\n",
    "\n",
    "\n",
    "NUM_WORKERS  = 4\n",
    "SEED         = 42\n",
    "\n",
    "PRINT_PATHS = False\n",
    "\n",
    "# ---- Tiling\n",
    "TILE_GRID        = (2, 2)  # 2×2 tiles per image (4 tiles)\n",
    "TILE_RESIZE_BASE = 448     # resize to 448, then crop 4×(224×224)\n",
    "FINAL_SIZE       = 224\n",
    "\n",
    "\n",
    "# ---- Backbone mode\n",
    "FEAT_MODE = \"resnet\"  # \"resnet\" | \"pvt\" | \"both\"\n",
    "\n",
    "# ---- Deterministic full-image augmentation repeats\n",
    "REPEATS_BY_DRAW = {\n",
    "    \"circle\":  4,  # fixed rotations over 360°\n",
    "    \"meander\": 2,  # deterministic Gaussian noise draws\n",
    "    \"spiral\":  2,  # deterministic Gaussian noise draws\n",
    "}\n",
    "\n",
    "# ---- Winning classical heads (fixed)\n",
    "WINNERS = {\n",
    "    \"circle\": Pipeline([\n",
    "        (\"scaler\", StandardScaler(with_mean=True, with_std=True)),\n",
    "        (\"clf\", KNeighborsClassifier(n_neighbors=1, weights=\"uniform\", p=1, metric=\"minkowski\", leaf_size=15)),\n",
    "    ]),\n",
    "    \"meander\": Pipeline([\n",
    "        (\"clf\", DecisionTreeClassifier(\n",
    "            random_state=SEED, criterion=\"gini\", max_depth=None,\n",
    "            min_samples_split=2, min_samples_leaf=1, max_features=None, class_weight=None\n",
    "        )),\n",
    "    ]),\n",
    "    \"spiral\": Pipeline(\n",
    "        [\n",
    "         (\n",
    "                \"clf\",\n",
    "                KNeighborsClassifier(\n",
    "                    n_neighbors=1,\n",
    "                    weights=\"uniform\",\n",
    "                    p=1,\n",
    "                    metric=\"minkowski\",\n",
    "                    leaf_size=15,\n",
    "                ),\n",
    "        ),\n",
    "    ]),\n",
    "}\n",
    "\n",
    "# =========================\n",
    "# Repro / determinism\n",
    "# =========================\n",
    "def set_seed(seed: int = 42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.benchmark = False          # [DET]\n",
    "    torch.backends.cudnn.deterministic = True       # [DET]\n",
    "    torch.backends.cuda.matmul.allow_tf32 = False   # [DET]\n",
    "    torch.backends.cudnn.allow_tf32 = False         # [DET]\n",
    "    torch.use_deterministic_algorithms(True)        # [DET]\n",
    "set_seed(SEED)\n",
    "\n",
    "def _seed_from_key(base_seed: int, *parts: str) -> int:  # [DET]\n",
    "    h = hashlib.sha256()\n",
    "    h.update(str(base_seed).encode())\n",
    "    for p in parts:\n",
    "        h.update(str(p).encode())\n",
    "    return int.from_bytes(h.digest()[:8], \"little\")\n",
    "\n",
    "def _worker_init_fn(worker_id: int):  # [DET]\n",
    "    ws = torch.initial_seed() % (2**32)\n",
    "    np.random.seed(ws)\n",
    "    random.seed(ws)\n",
    "\n",
    "def _make_loader(dataset, *, shuffle: bool, num_workers: int, base_seed: int, key: str, batch_size: int):  # [DET]\n",
    "    g = torch.Generator(device=\"cpu\")\n",
    "    g.manual_seed(_seed_from_key(base_seed, key))\n",
    "    return DataLoader(\n",
    "        dataset,\n",
    "        batch_size=batch_size, shuffle=shuffle, num_workers=num_workers,\n",
    "        pin_memory=True, worker_init_fn=_worker_init_fn, generator=g,\n",
    "        persistent_workers=False, drop_last=False,\n",
    "    )\n",
    "\n",
    "def make_fold_seed(*parts: str) -> int:\n",
    "    h = hashlib.sha256()\n",
    "    h.update(str(SEED).encode())\n",
    "    for p in parts:\n",
    "        h.update(str(p).encode())\n",
    "    return int.from_bytes(h.digest()[:8], \"little\")\n",
    "\n",
    "def reseed_for_fold(draw: str, fold_idx: int):\n",
    "    s = make_fold_seed(\"fold\", draw, str(fold_idx))\n",
    "    random.seed(s)\n",
    "    np.random.seed(s % (2**32))\n",
    "    torch.manual_seed(s)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(s)\n",
    "\n",
    "# ------------------------------------------------------\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "# =========================\n",
    "# Data discovery (DETERMINISTIC)\n",
    "# =========================\n",
    "_SUBJ_PAT = re.compile(r\"(?i)-([HP])0*(\\d+)$\")\n",
    "_SUBJ_ANY = re.compile(r\"(?i)-([HP])0*(\\d+)\\b\")\n",
    "\n",
    "def extract_subject_id(fp: str) -> str:\n",
    "    stem = Path(fp).stem\n",
    "    m = _SUBJ_PAT.search(stem) or _SUBJ_ANY.search(stem)\n",
    "    if not m:\n",
    "        # For image-wise evaluation, subject is irrelevant; but keep parser strict\n",
    "        raise ValueError(f\"[subject_id] Could not parse subject from: {fp}\")\n",
    "    prefix = m.group(1).upper()\n",
    "    num = str(int(m.group(2)))\n",
    "    return f\"{prefix}{num}\"\n",
    "\n",
    "_DRAW_MAP = {\n",
    "    \"circle\":  [\"circle\", \"circ\"],\n",
    "    \"meander\": [\"meander\", \"meand\", \"wave\", \"wav\"],\n",
    "    \"spiral\":  [\"spiral\", \"spir\", \"sp\"],\n",
    "}\n",
    "\n",
    "def _norm_draw_folder(name: str):\n",
    "    s = name.lower()\n",
    "    for canon, toks in _DRAW_MAP.items():\n",
    "        if any(tok == s or tok in s for tok in toks):\n",
    "            return canon\n",
    "    return None\n",
    "\n",
    "def discover_items_tree(data_root: Path) -> List[Tuple[str, int, str, str]]:\n",
    "    exts = {\".jpg\", \".jpeg\", \".png\", \".bmp\", \".tif\", \".tiff\"}\n",
    "    items: List[Tuple[str, int, str, str]] = []\n",
    "    seen: set[str] = set()\n",
    "\n",
    "    for hlab_name, lab in [(\"Healthy\", 0), (\"Patient\", 1)]:\n",
    "        lab_dir = data_root / hlab_name\n",
    "        if not lab_dir.exists():\n",
    "            print(f\"[warn] Missing folder: {lab_dir}\")\n",
    "            continue\n",
    "        for sub in sorted(lab_dir.iterdir(), key=lambda p: p.name.lower()):\n",
    "            if not sub.is_dir():\n",
    "                continue\n",
    "            d = _norm_draw_folder(sub.name)\n",
    "            if d is None:\n",
    "                continue\n",
    "            files = sorted(\n",
    "                (p for p in sub.rglob(\"*\") if p.is_file() and p.suffix.lower() in exts),\n",
    "                key=lambda p: str(p).lower(),\n",
    "            )\n",
    "            for p in files:\n",
    "                rp = str(p.resolve())\n",
    "                if rp in seen:\n",
    "                    continue\n",
    "                seen.add(rp)\n",
    "                sid = extract_subject_id(rp)\n",
    "                items.append((rp, lab, d, sid))\n",
    "\n",
    "    items.sort(key=lambda t: (t[1], t[2], t[3], t[0]))\n",
    "    print(f\"[info] Found {len(items)} images\")\n",
    "    if items:\n",
    "        print(\"  by label    :\", Counter([lab for _, lab, _, _ in items]))\n",
    "        print(\"  by draw type:\", Counter([d for _, _, d, _ in items]))\n",
    "        print(\"  subjects    :\", len(set([sid for *_, sid in items])))\n",
    "    return items\n",
    "\n",
    "# =========================\n",
    "# Transforms / Tiling (per-image max only; NO mean/std)\n",
    "# =========================\n",
    "class PerImageMaxNormalize(object):\n",
    "    def __call__(self, img: torch.Tensor):\n",
    "        cmax = torch.amax(img, dim=(1, 2), keepdim=True)\n",
    "        return img / (cmax + 1e-8)\n",
    "\n",
    "_RESIZE_448 = transforms.Resize((TILE_RESIZE_BASE, TILE_RESIZE_BASE), interpolation=InterpolationMode.BILINEAR)\n",
    "_TO_TENSOR  = transforms.ToTensor()\n",
    "_TO_PIL     = transforms.ToPILImage()\n",
    "_NORM_PERIMG= PerImageMaxNormalize()\n",
    "\n",
    "def _resize_to_base(pil_img: Image.Image) -> Image.Image:\n",
    "    return _RESIZE_448(pil_img)\n",
    "\n",
    "def _crop_tile_from_resized(pil_img_448: Image.Image, tile_index: int, rows: int = 2, cols: int = 2) -> Image.Image:\n",
    "    W, H = pil_img_448.size\n",
    "    tile_w, tile_h = W // cols, H // rows\n",
    "    r = tile_index // cols\n",
    "    c = tile_index % cols\n",
    "    left = c * tile_w\n",
    "    top  = r * tile_h\n",
    "    return pil_img_448.crop((left, top, left + tile_w, top + tile_h))\n",
    "\n",
    "def _tile_to_tensor(pil_tile: Image.Image) -> torch.Tensor:\n",
    "    t = _TO_TENSOR(pil_tile)     # [0,1]\n",
    "    t = _NORM_PERIMG(t)\n",
    "    return t\n",
    "\n",
    "# =========================\n",
    "# Deterministic full-image augmentation (applied BEFORE tiling)\n",
    "# =========================\n",
    "def _hash_int(s: str) -> int:\n",
    "    return int.from_bytes(hashlib.sha256(s.encode()).digest()[:8], \"little\")\n",
    "\n",
    "def _angle_for_repeat(total_repeats: int, repeat_idx: int, min_angle: float = 0.0, max_angle: float = 360.0) -> float:\n",
    "    if total_repeats <= 1:\n",
    "        return 0.0\n",
    "    step = (max_angle - min_angle) / total_repeats\n",
    "    return min_angle + step * (repeat_idx % total_repeats)\n",
    "\n",
    "def augment_full_image_deterministic(pil_img: Image.Image, draw: str, fp: str, repeat_idx: int) -> Image.Image:\n",
    "    img = _resize_to_base(pil_img)\n",
    "    if draw == \"circle\":\n",
    "        angle = _angle_for_repeat(REPEATS_BY_DRAW.get(\"circle\", 1), repeat_idx)\n",
    "        img = transforms.functional.rotate(\n",
    "            img, angle, interpolation=InterpolationMode.BILINEAR, expand=False, fill=255\n",
    "        )\n",
    "        return img\n",
    "    repeats = REPEATS_BY_DRAW.get(draw, 1)\n",
    "    if repeats > 1:\n",
    "        key = f\"{SEED}|noise|{draw}|{fp}|rep{repeat_idx}\"\n",
    "        gen = torch.Generator(device=\"cpu\")\n",
    "        gen.manual_seed(_hash_int(key))\n",
    "        x = _TO_TENSOR(img)\n",
    "        std = 0.003\n",
    "        noise = torch.randn(x.size(), generator=gen) * std\n",
    "        x = (x + noise).clamp(0.0, 1.0)\n",
    "        img = _TO_PIL(x)\n",
    "    return img\n",
    "\n",
    "# =========================\n",
    "# Datasets\n",
    "# =========================\n",
    "def _prf(tp: int, fp: int, fn: int):\n",
    "    prec = tp / (tp + fp) if (tp + fp) > 0 else 0.0\n",
    "    rec  = tp / (tp + fn) if (tp + fn) > 0 else 0.0\n",
    "    f1   = (2*prec*rec/(prec+rec)) if (prec+rec) > 0 else 0.0\n",
    "    return prec, rec, f1\n",
    "\n",
    "class TrainTilesAugFirstDataset(Dataset):\n",
    "    def __init__(self, items):\n",
    "        self.records = []  # (fp, lab, draw, sid, repeat_idx, tile_index)\n",
    "        for fp, lab, d, sid in items:\n",
    "            repeats = max(1, int(REPEATS_BY_DRAW.get(d, 1)))\n",
    "            for rep in range(repeats):\n",
    "                for tile_idx in range(TILE_GRID[0] * TILE_GRID[1]):\n",
    "                    self.records.append((fp, int(lab), d, sid, rep, tile_idx))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.records)\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        fp, lab, d, sid, rep, tile_idx = self.records[i]\n",
    "        pil_img = Image.open(fp).convert(\"RGB\")\n",
    "        aug_img = augment_full_image_deterministic(pil_img, d, fp, rep)\n",
    "        pil_tile = _crop_tile_from_resized(aug_img, tile_idx, *TILE_GRID)\n",
    "        x = _tile_to_tensor(pil_tile)\n",
    "        return x, lab\n",
    "\n",
    "class TilesWithMetaDataset(Dataset):\n",
    "    def __init__(self, items):\n",
    "        self.records = []  # (fp, lab, sid, tile_index)\n",
    "        for fp, lab, _d, sid in items:\n",
    "            for tile_idx in range(TILE_GRID[0] * TILE_GRID[1]):\n",
    "                self.records.append((fp, int(lab), sid, tile_idx))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.records)\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        fp, lab, sid, tile_idx = self.records[i]\n",
    "        pil_img = Image.open(fp).convert(\"RGB\")\n",
    "        img448 = _resize_to_base(pil_img)\n",
    "        pil_tile = _crop_tile_from_resized(img448, tile_idx, *TILE_GRID)\n",
    "        x = _tile_to_tensor(pil_tile)\n",
    "        return x, lab, sid, fp\n",
    "\n",
    "# =========================\n",
    "# Backbone model (feature extractor)\n",
    "# =========================\n",
    "class ResNetPVTRep(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        mode: str = \"both\",\n",
    "        *,\n",
    "        resnet_pretrained: bool = True,\n",
    "        pvt_pretrained: bool = False,\n",
    "        hidden1: int = 512,\n",
    "        hidden2: Optional[int] = 512,\n",
    "        dropout: float = 0.0,\n",
    "        freeze_backbones: bool = False,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        assert mode in {\"resnet\", \"pvt\", \"both\"}\n",
    "        self.mode = mode\n",
    "\n",
    "        self.resnet = None\n",
    "        res_dim = 0\n",
    "        if mode in {\"resnet\", \"both\"}:\n",
    "            self.resnet = resnet18(\n",
    "                weights=ResNet18_Weights.IMAGENET1K_V1 if resnet_pretrained else None\n",
    "            )\n",
    "            res_dim = self.resnet.fc.in_features  # 512\n",
    "            self.resnet.fc = nn.Identity()\n",
    "\n",
    "        self.pvt = None\n",
    "        pvt_dim = 0\n",
    "        if mode in {\"pvt\", \"both\"}:\n",
    "            self.pvt = timm.create_model(\n",
    "                \"pvt_v2_b1\", pretrained=pvt_pretrained, num_classes=0, global_pool=\"avg\",\n",
    "            )\n",
    "            pvt_dim = getattr(self.pvt, \"num_features\", 512)\n",
    "\n",
    "        fused_dim = res_dim + pvt_dim\n",
    "        layers = [nn.Linear(fused_dim, hidden1), nn.ReLU(inplace=True)]\n",
    "        if dropout and dropout > 0:\n",
    "            layers.append(nn.Dropout(dropout))\n",
    "        if hidden2 is None:\n",
    "            layers.append(nn.Linear(hidden1, 2))\n",
    "        else:\n",
    "            layers.extend([nn.Linear(hidden1, hidden2), nn.ReLU(inplace=True), nn.Linear(hidden2, 2)])\n",
    "        self.head = nn.Sequential(*layers)\n",
    "\n",
    "        if freeze_backbones:\n",
    "            if self.resnet is not None:\n",
    "                for p in self.resnet.parameters(): p.requires_grad = False\n",
    "            if self.pvt is not None:\n",
    "                for p in self.pvt.parameters(): p.requires_grad = False\n",
    "\n",
    "    def forward(self, x):\n",
    "        feats = []\n",
    "        if self.resnet is not None:\n",
    "            feats.append(self.resnet(x))\n",
    "        if self.pvt is not None:\n",
    "            feats.append(self.pvt(x))\n",
    "        z = feats[0] if len(feats) == 1 else torch.cat(feats, dim=1)\n",
    "        return self.head(z)\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def tile_features(self, x):\n",
    "        feats = []\n",
    "        if self.resnet is not None:\n",
    "            feats.append(self.resnet(x))\n",
    "        if self.pvt is not None:\n",
    "            feats.append(self.pvt(x))\n",
    "        return feats[0] if len(feats) == 1 else torch.cat(feats, dim=1)\n",
    "\n",
    "def make_backbone_model(\n",
    "    mode: str = \"both\",\n",
    "    *,\n",
    "    hidden1: int = 128,\n",
    "    hidden2: Optional[int] = None,\n",
    "    dropout: float = 0.0,\n",
    "    freeze_backbones: bool = False,\n",
    "    resnet_pretrained: bool = True,\n",
    "    pvt_pretrained: bool = True,\n",
    ") -> nn.Module:\n",
    "    return ResNetPVTRep(\n",
    "        mode=mode,\n",
    "        resnet_pretrained=resnet_pretrained,\n",
    "        pvt_pretrained=pvt_pretrained,\n",
    "        hidden1=hidden1,\n",
    "        hidden2=hidden2,\n",
    "        dropout=dropout,\n",
    "        freeze_backbones=freeze_backbones,\n",
    "    )\n",
    "\n",
    "# =========================\n",
    "# Image-level feature extraction (mean over tiles)\n",
    "# =========================\n",
    "@torch.no_grad()\n",
    "def collect_image_features(model: ResNetPVTRep, items: List[Tuple[str,int,str,str]], device):\n",
    "    ds = TilesWithMetaDataset(items)\n",
    "    dl = _make_loader(ds, batch_size=32, shuffle=False, num_workers=NUM_WORKERS, base_seed=SEED, key=\"FEATS\",)\n",
    "    model.eval()\n",
    "    feats_by_key: Dict[str, List[np.ndarray]] = defaultdict(list)\n",
    "    labels_by_key: Dict[str, int] = {}\n",
    "    for xb, yb, sidb, imgkey in dl:\n",
    "        xb = xb.to(device, non_blocking=True)\n",
    "        z = model.tile_features(xb).detach().cpu().numpy()\n",
    "        yb = yb.numpy()\n",
    "        for zi, lab, k in zip(z, yb, imgkey):\n",
    "            feats_by_key[k].append(zi)\n",
    "            labels_by_key[k] = int(lab)\n",
    "    X_list, y_list, key_list = [], [], []\n",
    "    for k in sorted(feats_by_key.keys()):\n",
    "        arr = np.stack(feats_by_key[k], axis=0)  # [num_tiles, D]\n",
    "        X_list.append(arr.mean(axis=0))          # mean over tiles → D\n",
    "        y_list.append(labels_by_key[k])\n",
    "        key_list.append(k)\n",
    "    X = np.stack(X_list, axis=0) if X_list else np.empty((0, 1))\n",
    "    y = np.asarray(y_list, dtype=np.int64)\n",
    "    return X, y, key_list\n",
    "\n",
    "# =========================\n",
    "# One-draw train & eval (image-wise)\n",
    "# =========================\n",
    "def train_one_draw_and_eval_imagewise(\n",
    "    train_items: List[Tuple[str,int,str,str]],\n",
    "    test_items:  List[Tuple[str,int,str,str]],\n",
    "    draw_name: str, fold_idx: int, device, feat_mode=FEAT_MODE\n",
    "):\n",
    "    reseed_for_fold(draw_name, fold_idx)\n",
    "\n",
    "    ep = EPOCHS_FN[draw_name]; lr = LR_INIT[draw_name]; bs = BATCH_SIZE[draw_name]\n",
    "    ls = LS_EPS[draw_name];    wd = WEIGHT_DECAY[draw_name]\n",
    "    hp_tag = f\"ep{ep}_lr{lr:.4g}_bs{bs}_ls{ls}_wd{wd}\"\n",
    "\n",
    "    dl_tr = _make_loader(\n",
    "        TrainTilesAugFirstDataset(train_items),\n",
    "        shuffle=True, num_workers=NUM_WORKERS, base_seed=SEED,\n",
    "        key=f\"TILE-TRAIN|{draw_name}|fold{fold_idx}|{hp_tag}\", batch_size=bs\n",
    "    )\n",
    "\n",
    "    # Backbone\n",
    "    feat_mode_per_draw = \"both\" if draw_name == \"spiral\" else \"resnet\"\n",
    "\n",
    "    # Fine-tune tile model (same as original settings)\n",
    "    model = make_backbone_model(\n",
    "        mode=feat_mode_per_draw,\n",
    "        hidden1=128,\n",
    "        hidden2=None,\n",
    "        dropout=0.0,\n",
    "        freeze_backbones=False,\n",
    "        resnet_pretrained=True,\n",
    "        pvt_pretrained=(feat_mode_per_draw == \"both\"),  # enable PVT weights for spiral\n",
    "    ).to(device)\n",
    "\n",
    "    opt = torch.optim.AdamW(model.parameters(), lr=lr, weight_decay=wd)\n",
    "    sched = torch.optim.lr_scheduler.StepLR(opt, step_size=7, gamma=0.1)\n",
    "    crit = nn.CrossEntropyLoss(label_smoothing=ls)\n",
    "\n",
    "    for ep_i in range(1, ep + 1):\n",
    "        model.train()\n",
    "        corr = tot = 0\n",
    "        for xb, yb in dl_tr:\n",
    "            xb, yb = xb.to(device, non_blocking=True), torch.as_tensor(yb, device=device)\n",
    "            opt.zero_grad(set_to_none=True)\n",
    "            logits = model(xb)\n",
    "            loss = crit(logits, yb)\n",
    "            loss.backward(); opt.step()\n",
    "            corr += (logits.argmax(1) == yb).sum().item()\n",
    "            tot  += yb.numel()\n",
    "        print(f\"[{draw_name:7s}][Fold {fold_idx:02d}][Ep {ep_i:02d}] train_tile_acc={corr/max(1,tot):.3f} | lr={opt.param_groups[0]['lr']:.6f}\")\n",
    "        sched.step()\n",
    "\n",
    "    # Save backbone\n",
    "    (OUTDIR / draw_name).mkdir(parents=True, exist_ok=True)\n",
    "    torch.save(model.state_dict(), OUTDIR / draw_name / f\"WINSIMG_{draw_name}_fold{fold_idx}.pth\")\n",
    "\n",
    "    # Image features\n",
    "    Xtr, ytr, _keys_tr = collect_image_features(model, train_items, device)\n",
    "    Xte, yte,  _keys_te = collect_image_features(model, test_items,  device)\n",
    "    print(f\"[{draw_name:7s}][Fold {fold_idx:02d}] Feature dim: {Xtr.shape[1]}  (Xtr={Xtr.shape}, Xte={Xte.shape})\")\n",
    "\n",
    "    # Winner head\n",
    "    clf = WINNERS[draw_name]\n",
    "    clf.fit(Xtr, ytr)\n",
    "    yhat = clf.predict(Xte)\n",
    "\n",
    "    # Image-level metrics\n",
    "    tp = int(((yhat == 1) & (yte == 1)).sum())\n",
    "    fp = int(((yhat == 1) & (yte == 0)).sum())\n",
    "    tn = int(((yhat == 0) & (yte == 0)).sum())\n",
    "    fn = int(((yhat == 0) & (yte == 1)).sum())\n",
    "    acc = (tp + tn) / max(1, (tp + fp + tn + fn))\n",
    "    P  = tp / max(1, (tp + fp))\n",
    "    R  = tp / max(1, (tp + fn))\n",
    "    F1 = (2*P*R) / max(1e-12, (P+R))\n",
    "\n",
    "    print(f\"[{draw_name:7s}][Fold {fold_idx:02d}] IMAGE TEST: acc={acc:.3f}  prec={P:.3f}  recall={R:.3f}  f1={F1:.3f}  [tp={tp} fp={fp} tn={tn} fn={fn}]\")\n",
    "    return {\"tp\": tp, \"fp\": fp, \"tn\": tn, \"fn\": fn, \"acc\": acc}\n",
    "\n",
    "# =========================\n",
    "# 5-fold driver — IMAGE-WISE (leaky-by-subject on purpose)\n",
    "# =========================\n",
    "def run_imagewise_5fold_winners(items_all, device, seed=SEED, feat_mode=FEAT_MODE):\n",
    "    print(\"\\n=== IMAGE-WISE 5-FOLD CV (SUBJECTS IGNORED) ===\")\n",
    "\n",
    "    # Per-draw accumulators\n",
    "    per_draw_fold_accs = {d: [] for d in DRAW_TYPES}    # macro (mean across folds)\n",
    "    per_draw_counts    = {d: {\"tp\":0,\"fp\":0,\"tn\":0,\"fn\":0} for d in DRAW_TYPES}  # micro pooled\n",
    "\n",
    "    for d in DRAW_TYPES:\n",
    "        # Collect all items of this draw (image-wise split)\n",
    "        draw_items = [it for it in items_all if it[2] == d]\n",
    "        if not draw_items:\n",
    "            print(f\"[{d}] No items, skipping.\")\n",
    "            continue\n",
    "\n",
    "        # Build image-wise labels (stratify by label, NOT by subject)\n",
    "        y_img = np.array([lab for (_fp, lab, _dr, _sid) in draw_items], dtype=int)\n",
    "\n",
    "        skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=seed % (2**32 - 1))\n",
    "\n",
    "        print(\"\\n\" + \"#\"*80)\n",
    "        print(f\"############## IMAGE-WISE CV — DRAW {d.upper()} ##############\")\n",
    "        print(\"#\"*80 + \"\\n\")\n",
    "\n",
    "        for fidx, (tr_idx, te_idx) in enumerate(skf.split(np.arange(len(draw_items)), y_img), 1):\n",
    "            tr_items = [draw_items[i] for i in tr_idx]\n",
    "            te_items = [draw_items[i] for i in te_idx]\n",
    "\n",
    "            # Ensure both classes exist in train fold\n",
    "            if len({lab for _fp, lab, _dr, _sid in tr_items}) < 2:\n",
    "                print(f\"[{d:7s}][Fold {fidx:02d}] Skipped (class collapse).\")\n",
    "                continue\n",
    "\n",
    "            counts = train_one_draw_and_eval_imagewise(tr_items, te_items, d, fidx, device, feat_mode)\n",
    "            per_draw_fold_accs[d].append(counts[\"acc\"])\n",
    "            for k in (\"tp\",\"fp\",\"tn\",\"fn\"):\n",
    "                per_draw_counts[d][k] += counts[k]\n",
    "\n",
    "        # Per-draw summaries\n",
    "        if per_draw_fold_accs[d]:\n",
    "            macro_acc = float(np.mean(per_draw_fold_accs[d]))\n",
    "            print(f\"\\n=== {d.upper()} — IMAGE ACCURACY (MACRO over folds) ===\")\n",
    "            print(f\"{d:8s}: macro_img_acc={macro_acc:.4f}  (from {len(per_draw_fold_accs[d])} folds)\")\n",
    "        else:\n",
    "            print(f\"\\n=== {d.upper()} — IMAGE ACCURACY (MACRO) ===\")\n",
    "            print(f\"{d:8s}: n/a (no valid folds)\")\n",
    "\n",
    "        c = per_draw_counts[d]\n",
    "        tot = c[\"tp\"] + c[\"fp\"] + c[\"tn\"] + c[\"fn\"]\n",
    "        if tot > 0:\n",
    "            P,R = (c[\"tp\"]/max(1,(c[\"tp\"]+c[\"fp\"]))), (c[\"tp\"]/max(1,(c[\"tp\"]+c[\"fn\"])))\n",
    "            F1  = (2*P*R)/max(1e-12,(P+R))\n",
    "            acc = (c[\"tp\"] + c[\"tn\"]) / tot\n",
    "            print(f\"\\n=== {d.upper()} — IMAGE PRF (MICRO pooled) ===\")\n",
    "            print(f\"{d:8s}: acc={acc:.3f}  prec={P:.3f}  recall={R:.3f}  f1={F1:.3f}  \"\n",
    "                  f\"[tp={c['tp']} fp={c['fp']} tn={c['tn']} fn={c['fn']}]\")\n",
    "        else:\n",
    "            print(f\"\\n=== {d.upper()} — IMAGE PRF (MICRO) ===\")\n",
    "            print(f\"{d:8s}: n/a\")\n",
    "\n",
    "    return per_draw_fold_accs, per_draw_counts\n",
    "\n",
    "# =========================\n",
    "# Kickoff\n",
    "# =========================\n",
    "if __name__ == \"__main__\":\n",
    "    OUTDIR.mkdir(parents=True, exist_ok=True)\n",
    "    items_all = discover_items_tree(DATA_ROOT)\n",
    "    _macro, _micro = run_imagewise_5fold_winners(items_all, device, seed=SEED, feat_mode=FEAT_MODE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c805a368-4077-45f4-b38c-26b997b30283",
   "metadata": {},
   "source": [
    "### _"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "167264b1-26cd-4d3a-b4f8-ce9d4b81c321",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
