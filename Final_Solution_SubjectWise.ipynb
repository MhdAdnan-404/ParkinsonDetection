{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e3dbad8-ce2d-479f-9a7f-4088e78ec4e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "# =========================\n",
    "# Determinism (set BEFORE importing torch)\n",
    "# =========================\n",
    "import os  # [DET]\n",
    "\n",
    "os.environ.setdefault(\"CUBLAS_WORKSPACE_CONFIG\", \":16:8\")  # [DET]\n",
    "\n",
    "import re\n",
    "from pathlib import Path\n",
    "from collections import Counter, defaultdict\n",
    "from typing import List, Tuple, Dict, Optional\n",
    "\n",
    "import numpy as np\n",
    "import random\n",
    "import hashlib  # [DET]\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\n",
    "    \"ignore\", message=\".*gpu_hist.*deprecated.*\", category=UserWarning\n",
    ")\n",
    "warnings.filterwarnings(\n",
    "    \"ignore\",\n",
    "    message='.*Parameters: { \"predictor\" } are not used.*',\n",
    "    category=UserWarning,\n",
    ")\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from torchvision.transforms import InterpolationMode\n",
    "from torchvision.models import resnet18, ResNet18_Weights\n",
    "from PIL import Image\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "import timm\n",
    "\n",
    "# =========================\n",
    "# Config\n",
    "# =========================\n",
    "DATA_ROOT = Path(r\"DataSet\")\n",
    "OUTDIR = Path(\"checkpoints_subject5cv_per_draw_tiles_WINS\")\n",
    "\n",
    "DRAW_TYPES = [\"circle\", \"meander\", \"spiral\"]\n",
    "\n",
    "EPOCHS_FN = {\"circle\": 5, \"meander\": 10, \"spiral\": 5}\n",
    "LR_INIT = {\"circle\": 3.16e-4, \"meander\": 1e-3, \"spiral\": 3.16e-4}\n",
    "BATCH_SIZE = {\"circle\": 64, \"meander\": 16, \"spiral\": 16}\n",
    "LS_EPS = {\"circle\": 0.05, \"meander\": 0.05, \"spiral\": 0.0}\n",
    "WEIGHT_DECAY = {\"circle\": 1e-4, \"meander\": 0.0, \"spiral\": 1e-4}\n",
    "NUM_WORKERS = 4\n",
    "SEED = 42\n",
    "\n",
    "PRINT_PATHS = False\n",
    "\n",
    "# ---- Tiling\n",
    "TILE_GRID = (2, 2)  # 2×2 tiles per image\n",
    "TILE_RESIZE_BASE = 448  # resize to 448, then crop 4×(224×224)\n",
    "FINAL_SIZE = 224\n",
    "\n",
    "# ---- Feature backbone mode (your best runs used resnet features)\n",
    "FEAT_MODE = \"resnet\"\n",
    "\n",
    "# ---- WINNING CLASSIFIER SPECS (fixed; from your “best” logs)\n",
    "# Circle (KNN): scaler=StandardScaler, no PCA, n_neighbors=1, p=1, weights=uniform, leaf_size=15\n",
    "# Meander (DT):  gini, max_depth=None, min_samples_split=2, min_samples_leaf=1, max_features=None, class_weight=None\n",
    "# Spiral (RF):   n_estimators=100, max_depth=None, min_samples_split=2, min_samples_leaf=1, max_features='sqrt',\n",
    "#                class_weight=None, n_jobs=-1\n",
    "WINNERS = {\n",
    "    \"circle\": Pipeline(\n",
    "        [\n",
    "            (\"scaler\", StandardScaler(with_mean=True, with_std=True)),\n",
    "            (\n",
    "                \"clf\",\n",
    "                KNeighborsClassifier(\n",
    "                    n_neighbors=1,\n",
    "                    weights=\"uniform\",\n",
    "                    p=1,\n",
    "                    metric=\"minkowski\",\n",
    "                    leaf_size=15,\n",
    "                ),\n",
    "            ),\n",
    "        ]\n",
    "    ),\n",
    "    \"meander\": Pipeline(\n",
    "        [\n",
    "            (\n",
    "                \"clf\",\n",
    "                DecisionTreeClassifier(\n",
    "                    random_state=SEED,\n",
    "                    criterion=\"gini\",\n",
    "                    max_depth=None,\n",
    "                    min_samples_split=2,\n",
    "                    min_samples_leaf=1,\n",
    "                    max_features=None,\n",
    "                    class_weight=None,\n",
    "                ),\n",
    "            ),\n",
    "        ]\n",
    "    ),\n",
    "    \"spiral\": Pipeline(\n",
    "        [\n",
    "            (\n",
    "                \"clf\",\n",
    "                KNeighborsClassifier(\n",
    "                    n_neighbors=1,\n",
    "                    weights=\"uniform\",\n",
    "                    p=1,\n",
    "                    metric=\"minkowski\",\n",
    "                    leaf_size=15,\n",
    "                ),\n",
    "            ),\n",
    "        ]\n",
    "    ),\n",
    "}\n",
    "\n",
    "# =========================\n",
    "# Repro / determinism\n",
    "# =========================\n",
    "def set_seed(seed: int = 42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.benchmark = False  # [DET]\n",
    "    torch.backends.cudnn.deterministic = True  # [DET]\n",
    "    torch.backends.cuda.matmul.allow_tf32 = False  # [DET]\n",
    "    torch.backends.cudnn.allow_tf32 = False  # [DET]\n",
    "    torch.use_deterministic_algorithms(True)  # [DET]\n",
    "\n",
    "\n",
    "set_seed(SEED)\n",
    "\n",
    "\n",
    "# ---------- Deterministic DataLoader helpers ----------\n",
    "def _seed_from_key(base_seed: int, *parts: str) -> int:  # [DET]\n",
    "    h = hashlib.sha256()\n",
    "    h.update(str(base_seed).encode())\n",
    "    for p in parts:\n",
    "        h.update(str(p).encode())\n",
    "    return int.from_bytes(h.digest()[:8], \"little\")\n",
    "\n",
    "\n",
    "def _worker_init_fn(worker_id: int):  # [DET]\n",
    "    ws = torch.initial_seed() % (2**32)\n",
    "    np.random.seed(ws)\n",
    "    random.seed(ws)\n",
    "\n",
    "\n",
    "def _make_loader(\n",
    "    dataset,\n",
    "    *,\n",
    "    shuffle: bool,\n",
    "    num_workers: int,\n",
    "    base_seed: int,\n",
    "    key: str,\n",
    "    batch_size: int,\n",
    "):  # [DET]\n",
    "    g = torch.Generator(device=\"cpu\")\n",
    "    g.manual_seed(_seed_from_key(base_seed, key))\n",
    "    return DataLoader(\n",
    "        dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=shuffle,\n",
    "        num_workers=num_workers,\n",
    "        pin_memory=True,\n",
    "        worker_init_fn=_worker_init_fn,\n",
    "        generator=g,\n",
    "        persistent_workers=False,\n",
    "        drop_last=False,\n",
    "    )\n",
    "\n",
    "\n",
    "# ---------- Fold-level reseed to lock init per draw×fold ----------\n",
    "def make_fold_seed(*parts: str) -> int:\n",
    "    h = hashlib.sha256()\n",
    "    h.update(str(SEED).encode())\n",
    "    for p in parts:\n",
    "        h.update(str(p).encode())\n",
    "    return int.from_bytes(h.digest()[:8], \"little\")\n",
    "\n",
    "\n",
    "def reseed_for_fold(draw: str, fold_idx: int):\n",
    "    s = make_fold_seed(\"fold\", draw, str(fold_idx))\n",
    "    random.seed(s)\n",
    "    np.random.seed(s % (2**32))\n",
    "    torch.manual_seed(s)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(s)\n",
    "\n",
    "\n",
    "# ------------------------------------------------------\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "# =========================\n",
    "# Data discovery (DETERMINISTIC)\n",
    "# =========================\n",
    "_SUBJ_PAT = re.compile(r\"(?i)-([HP])0*(\\d+)$\")\n",
    "_SUBJ_ANY = re.compile(r\"(?i)-([HP])0*(\\d+)\\b\")\n",
    "\n",
    "\n",
    "def extract_subject_id(fp: str) -> str:\n",
    "    stem = Path(fp).stem\n",
    "    m = _SUBJ_PAT.search(stem) or _SUBJ_ANY.search(stem)\n",
    "    if not m:\n",
    "        raise ValueError(f\"[subject_id] Could not parse subject from: {fp}\")\n",
    "    prefix = m.group(1).upper()\n",
    "    num = str(int(m.group(2)))\n",
    "    return f\"{prefix}{num}\"\n",
    "\n",
    "\n",
    "_DRAW_MAP = {\n",
    "    \"circle\": [\"circle\", \"circ\"],\n",
    "    \"meander\": [\"meander\", \"meand\", \"wave\", \"wav\"],\n",
    "    \"spiral\": [\"spiral\", \"spir\", \"sp\"],\n",
    "}\n",
    "\n",
    "\n",
    "def _norm_draw_folder(name: str):\n",
    "    s = name.lower()\n",
    "    for canon, toks in _DRAW_MAP.items():\n",
    "        if any(tok == s or tok in s for tok in toks):\n",
    "            return canon\n",
    "    return None\n",
    "\n",
    "\n",
    "def discover_items_tree(data_root: Path) -> List[Tuple[str, int, str, str]]:\n",
    "    exts = {\".jpg\", \".jpeg\", \".png\", \".bmp\", \".tif\", \".tiff\"}\n",
    "    items: List[Tuple[str, int, str, str]] = []\n",
    "    seen: set[str] = set()\n",
    "\n",
    "    for hlab_name, lab in [(\"Healthy\", 0), (\"Patient\", 1)]:\n",
    "        lab_dir = data_root / hlab_name\n",
    "        if not lab_dir.exists():\n",
    "            print(f\"[warn] Missing folder: {lab_dir}\")\n",
    "            continue\n",
    "        for sub in sorted(lab_dir.iterdir(), key=lambda p: p.name.lower()):\n",
    "            if not sub.is_dir():\n",
    "                continue\n",
    "            d = _norm_draw_folder(sub.name)\n",
    "            if d is None:\n",
    "                continue\n",
    "            files = sorted(\n",
    "                (p for p in sub.rglob(\"*\") if p.is_file() and p.suffix.lower() in exts),\n",
    "                key=lambda p: str(p).lower(),\n",
    "            )\n",
    "            for p in files:\n",
    "                rp = str(p.resolve())\n",
    "                if rp in seen:\n",
    "                    continue\n",
    "                seen.add(rp)\n",
    "                sid = extract_subject_id(rp)\n",
    "                items.append((rp, lab, d, sid))\n",
    "\n",
    "    items.sort(key=lambda t: (t[1], t[2], t[3], t[0]))\n",
    "    print(f\"[info] Found {len(items)} images\")\n",
    "    if items:\n",
    "        print(\"  by label    :\", Counter([lab for _, lab, _, _ in items]))\n",
    "        print(\"  by draw type:\", Counter([d for _, _, d, _ in items]))\n",
    "        print(\"  subjects    :\", len(set([sid for *_, sid in items])))\n",
    "    return items\n",
    "\n",
    "\n",
    "# =========================\n",
    "# Transforms / Tiling (per-image max only; NO mean/std)\n",
    "# =========================\n",
    "class PerImageMaxNormalize(object):\n",
    "    def __call__(self, img: torch.Tensor):\n",
    "        cmax = torch.amax(img, dim=(1, 2), keepdim=True)\n",
    "        return img / (cmax + 1e-8)\n",
    "\n",
    "\n",
    "_RESIZE_448 = transforms.Resize(\n",
    "    (TILE_RESIZE_BASE, TILE_RESIZE_BASE), interpolation=InterpolationMode.BILINEAR\n",
    ")\n",
    "_TO_TENSOR = transforms.ToTensor()\n",
    "_TO_PIL = transforms.ToPILImage()\n",
    "_NORM_PERIMG = PerImageMaxNormalize()\n",
    "\n",
    "\n",
    "def _resize_to_base(pil_img: Image.Image) -> Image.Image:\n",
    "    return _RESIZE_448(pil_img)\n",
    "\n",
    "\n",
    "def _crop_tile_from_resized(\n",
    "    pil_img_448: Image.Image, tile_index: int, rows: int = 2, cols: int = 2\n",
    ") -> Image.Image:\n",
    "    W, H = pil_img_448.size\n",
    "    tile_w, tile_h = W // cols, H // rows\n",
    "    r = tile_index // cols\n",
    "    c = tile_index % cols\n",
    "    left = c * tile_w\n",
    "    top = r * tile_h\n",
    "    return pil_img_448.crop((left, top, left + tile_w, top + tile_h))\n",
    "\n",
    "\n",
    "def _tile_to_tensor(pil_tile: Image.Image) -> torch.Tensor:\n",
    "    t = _TO_TENSOR(pil_tile)  # [0,1]\n",
    "    t = _NORM_PERIMG(t)\n",
    "    return t\n",
    "\n",
    "\n",
    "# =========================\n",
    "# Datasets (NO AUGMENTATION)\n",
    "# =========================\n",
    "class TrainTilesDataset(Dataset):\n",
    "    \"\"\"Each image is resized once and split into 2×2 tiles; no augmentation, no repeats.\"\"\"\n",
    "    def __init__(self, items):\n",
    "        self.records = []  # (fp, lab, draw, sid, tile_index)\n",
    "        for fp, lab, d, sid in items:\n",
    "            for tile_idx in range(TILE_GRID[0] * TILE_GRID[1]):\n",
    "                self.records.append((fp, int(lab), d, sid, tile_idx))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.records)\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        fp, lab, d, sid, tile_idx = self.records[i]\n",
    "        pil_img = Image.open(fp).convert(\"RGB\")\n",
    "        img448 = _resize_to_base(pil_img)\n",
    "        pil_tile = _crop_tile_from_resized(img448, tile_idx, *TILE_GRID)\n",
    "        x = _tile_to_tensor(pil_tile)\n",
    "        return x, lab\n",
    "\n",
    "\n",
    "class TilesWithMetaDataset(Dataset):\n",
    "    def __init__(self, items):\n",
    "        self.records = []  # (fp, lab, sid, tile_index)\n",
    "        for fp, lab, _d, sid in items:\n",
    "            for tile_idx in range(TILE_GRID[0] * TILE_GRID[1]):\n",
    "                self.records.append((fp, int(lab), sid, tile_idx))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.records)\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        fp, lab, sid, tile_idx = self.records[i]\n",
    "        pil_img = Image.open(fp).convert(\"RGB\")\n",
    "        img448 = _resize_to_base(pil_img)\n",
    "        pil_tile = _crop_tile_from_resized(img448, tile_idx, *TILE_GRID)\n",
    "        x = _tile_to_tensor(pil_tile)\n",
    "        return x, lab, sid, fp\n",
    "\n",
    "\n",
    "# =========================\n",
    "# Backbone model (feature extractor)\n",
    "# =========================\n",
    "class ResNetPVTRep(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        mode: str = \"both\",\n",
    "        *,\n",
    "        resnet_pretrained: bool = True,\n",
    "        pvt_pretrained: bool = False,\n",
    "        hidden1: int = 512,\n",
    "        hidden2: Optional[int] = 512,\n",
    "        dropout: float = 0.0,\n",
    "        freeze_backbones: bool = False,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        assert mode in {\"resnet\", \"pvt\", \"both\"}\n",
    "        self.mode = mode\n",
    "\n",
    "        self.resnet = None\n",
    "        res_dim = 0\n",
    "        if mode in {\"resnet\", \"both\"}:\n",
    "            self.resnet = resnet18(\n",
    "                weights=ResNet18_Weights.IMAGENET1K_V1 if resnet_pretrained else None\n",
    "            )\n",
    "            res_dim = self.resnet.fc.in_features  # 512\n",
    "            self.resnet.fc = nn.Identity()\n",
    "\n",
    "        self.pvt = None\n",
    "        pvt_dim = 0\n",
    "        if mode in {\"pvt\", \"both\"}:\n",
    "            self.pvt = timm.create_model(\n",
    "                \"pvt_v2_b1\",\n",
    "                pretrained=pvt_pretrained,\n",
    "                num_classes=0,\n",
    "                global_pool=\"avg\",\n",
    "            )\n",
    "            pvt_dim = getattr(self.pvt, \"num_features\", 512)\n",
    "\n",
    "        fused_dim = res_dim + pvt_dim\n",
    "\n",
    "        layers = [nn.Linear(fused_dim, hidden1), nn.ReLU(inplace=True)]\n",
    "        if dropout and dropout > 0:\n",
    "            layers.append(nn.Dropout(dropout))\n",
    "        if hidden2 is None:\n",
    "            layers.append(nn.Linear(hidden1, 2))\n",
    "        else:\n",
    "            layers.extend(\n",
    "                [\n",
    "                    nn.Linear(hidden1, hidden2),\n",
    "                    nn.ReLU(inplace=True),\n",
    "                    nn.Linear(hidden2, 2),\n",
    "                ]\n",
    "            )\n",
    "        self.head = nn.Sequential(*layers)\n",
    "\n",
    "        if freeze_backbones:\n",
    "            if self.resnet is not None:\n",
    "                for p in self.resnet.parameters():\n",
    "                    p.requires_grad = False\n",
    "            if self.pvt is not None:\n",
    "                for p in self.pvt.parameters():\n",
    "                    p.requires_grad = False\n",
    "\n",
    "    def forward(self, x):\n",
    "        feats = []\n",
    "        if self.resnet is not None:\n",
    "            feats.append(self.resnet(x))\n",
    "        if self.pvt is not None:\n",
    "            feats.append(self.pvt(x))\n",
    "        z = feats[0] if len(feats) == 1 else torch.cat(feats, dim=1)\n",
    "        return self.head(z)\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def tile_features(self, x):\n",
    "        feats = []\n",
    "        if self.resnet is not None:\n",
    "            feats.append(self.resnet(x))\n",
    "        if self.pvt is not None:\n",
    "            feats.append(self.pvt(x))\n",
    "        return feats[0] if len(feats) == 1 else torch.cat(feats, dim=1)\n",
    "\n",
    "\n",
    "def make_backbone_model(\n",
    "    mode: str = \"both\",\n",
    "    *,\n",
    "    hidden1: int = 128,\n",
    "    hidden2: Optional[int] = None,\n",
    "    dropout: float = 0.0,\n",
    "    freeze_backbones: bool = False,\n",
    "    resnet_pretrained: bool = True,\n",
    "    pvt_pretrained: bool = True,\n",
    ") -> nn.Module:\n",
    "    return ResNetPVTRep(\n",
    "        mode=mode,\n",
    "        resnet_pretrained=resnet_pretrained,\n",
    "        pvt_pretrained=pvt_pretrained,\n",
    "        hidden1=hidden1,\n",
    "        hidden2=hidden2,\n",
    "        dropout=dropout,\n",
    "        freeze_backbones=freeze_backbones,\n",
    "    )\n",
    "\n",
    "\n",
    "# =========================\n",
    "# Inference helpers (tile → image features)\n",
    "# =========================\n",
    "@torch.no_grad()\n",
    "def collect_image_features(\n",
    "    model: ResNetPVTRep, items: List[Tuple[str, int, str, str]], device\n",
    "):\n",
    "    ds = TilesWithMetaDataset(items)\n",
    "    dl = _make_loader(\n",
    "        ds,\n",
    "        batch_size=32,\n",
    "        shuffle=False,\n",
    "        num_workers=NUM_WORKERS,\n",
    "        base_seed=SEED,\n",
    "        key=\"FEATS\",\n",
    "    )\n",
    "    model.eval()\n",
    "\n",
    "    feats_by_key: Dict[str, List[np.ndarray]] = defaultdict(list)\n",
    "    labels_by_key: Dict[str, int] = {}\n",
    "    sid_by_key: Dict[str, str] = {}\n",
    "\n",
    "    for xb, yb, sidb, imgkey in dl:\n",
    "        xb = xb.to(device, non_blocking=True)\n",
    "        z = model.tile_features(xb).detach().cpu().numpy()\n",
    "        yb = yb.numpy()\n",
    "        for zi, lab, sid, k in zip(z, yb, sidb, imgkey):\n",
    "            feats_by_key[k].append(zi)\n",
    "            labels_by_key[k] = int(lab)\n",
    "            sid_by_key[k] = str(sid)\n",
    "\n",
    "    X_list, y_list, sid_list, key_list = [], [], [], []\n",
    "    for k in sorted(feats_by_key.keys()):\n",
    "        arr = np.stack(feats_by_key[k], axis=0)  # [num_tiles, D]\n",
    "        X_list.append(arr.mean(axis=0))  # mean over tiles → 512-D (or fused)\n",
    "        y_list.append(labels_by_key[k])\n",
    "        sid_list.append(sid_by_key[k])\n",
    "        key_list.append(k)\n",
    "    X = np.stack(X_list, axis=0) if X_list else np.empty((0, 1))\n",
    "    y = np.asarray(y_list, dtype=np.int64)\n",
    "    return X, y, sid_list, key_list\n",
    "\n",
    "\n",
    "# =========================\n",
    "# Subject helpers\n",
    "# =========================\n",
    "def majority_vote(int_list: List[int]):\n",
    "    if not int_list:\n",
    "        return None\n",
    "    z = int_list.count(0)\n",
    "    o = int_list.count(1)\n",
    "    return 1 if o > z else 0\n",
    "\n",
    "\n",
    "def subject_labels_from_items(items_all):\n",
    "    sid2lab = {}\n",
    "    for _fp, lab, _d, sid in items_all:\n",
    "        if sid in sid2lab:\n",
    "            assert sid2lab[sid] == lab, f\"Subject {sid} has mixed labels!\"\n",
    "        else:\n",
    "            sid2lab[sid] = lab\n",
    "    return sid2lab\n",
    "\n",
    "\n",
    "# =========================\n",
    "# Train one draw (tiles), then extract features and fit WINNER clf\n",
    "# =========================\n",
    "def train_one_draw_and_eval(\n",
    "    train_items, test_items, draw_name, fold_idx, device, feat_mode=FEAT_MODE\n",
    "):\n",
    "    train_sids = {sid for _fp, _lab, _d, sid in train_items}\n",
    "    test_sids = {sid for _fp, _lab, _d, sid in test_items}\n",
    "    assert train_sids.isdisjoint(test_sids), \"Leak: TRAIN and TEST share subjects!\"\n",
    "\n",
    "    reseed_for_fold(draw_name, fold_idx)\n",
    "\n",
    "    ep = EPOCHS_FN[draw_name]\n",
    "    lr = LR_INIT[draw_name]\n",
    "    bs = BATCH_SIZE[draw_name]\n",
    "    ls = LS_EPS[draw_name]\n",
    "    wd = WEIGHT_DECAY[draw_name]\n",
    "    hp_tag = f\"ep{ep}_lr{lr:.4g}_bs{bs}_ls{ls}_wd{wd}\"\n",
    "\n",
    "    dl_tr = _make_loader(\n",
    "        TrainTilesDataset(train_items),  # <-- no augmentation\n",
    "        shuffle=True,\n",
    "        num_workers=NUM_WORKERS,\n",
    "        base_seed=SEED,\n",
    "        key=f\"TILE-TRAIN|{draw_name}|fold{fold_idx}|{hp_tag}\",\n",
    "        batch_size=BATCH_SIZE[draw_name],\n",
    "    )\n",
    "\n",
    "    feat_mode_per_draw = \"both\" if draw_name == \"spiral\" else \"resnet\"\n",
    "\n",
    "    # Fine-tune tile model (same as original settings)\n",
    "    model = make_backbone_model(\n",
    "        mode=feat_mode_per_draw,\n",
    "        hidden1=128,\n",
    "        hidden2=None,\n",
    "        dropout=0.0,\n",
    "        freeze_backbones=False,\n",
    "        resnet_pretrained=True,\n",
    "        pvt_pretrained=(feat_mode_per_draw == \"both\"),  # enable PVT weights for spiral\n",
    "    ).to(device)\n",
    "\n",
    "    opt = torch.optim.AdamW(\n",
    "        model.parameters(), lr=LR_INIT[draw_name], weight_decay=WEIGHT_DECAY[draw_name]\n",
    "    )\n",
    "    sched = torch.optim.lr_scheduler.StepLR(opt, step_size=7, gamma=0.1)\n",
    "    crit = nn.CrossEntropyLoss(label_smoothing=LS_EPS[draw_name])\n",
    "\n",
    "    for ep in range(1, EPOCHS_FN[draw_name] + 1):\n",
    "        model.train()\n",
    "        corr = tot = 0\n",
    "        for xb, yb in dl_tr:\n",
    "            xb, yb = xb.to(device, non_blocking=True), torch.as_tensor(\n",
    "                yb, device=device\n",
    "            )\n",
    "            opt.zero_grad(set_to_none=True)\n",
    "            logits = model(xb)\n",
    "            loss = crit(logits, yb)\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "            corr += (logits.argmax(1) == yb).sum().item()\n",
    "            tot += yb.numel()\n",
    "        print(\n",
    "            f\"[{draw_name:7s}][Fold {fold_idx:02d}][Ep {ep:02d}] \"\n",
    "            f\"train_tile_acc={corr/max(1,tot):.3f} | lr={opt.param_groups[0]['lr']:.6f}\"\n",
    "        )\n",
    "        sched.step()\n",
    "\n",
    "    # Save backbone (optional)\n",
    "    (OUTDIR / draw_name).mkdir(parents=True, exist_ok=True)\n",
    "    torch.save(\n",
    "        model.state_dict(), OUTDIR / draw_name / f\"WINS_{draw_name}_fold{fold_idx}.pth\"\n",
    "    )\n",
    "\n",
    "    # ---- Extract per-image features\n",
    "    Xtr, ytr, _sid_tr, _keys_tr = collect_image_features(model, train_items, device)\n",
    "    Xte, yte, sid_te, _keys_te = collect_image_features(model, test_items, device)\n",
    "    print(\n",
    "        f\"[{draw_name:7s}][Fold {fold_idx:02d}] Feature dim: {Xtr.shape[1]}  (Xtr={Xtr.shape}, Xte={Xte.shape})\"\n",
    "    )\n",
    "\n",
    "    # ---- Fit WINNER classifier (fixed params)\n",
    "    clf = WINNERS[draw_name]\n",
    "    clf.fit(Xtr, ytr)\n",
    "    yhat = clf.predict(Xte)\n",
    "\n",
    "    # ---- Per-draw image metrics\n",
    "    tp = int(((yhat == 1) & (yte == 1)).sum())\n",
    "    fp = int(((yhat == 1) & (yte == 0)).sum())\n",
    "    tn = int(((yhat == 0) & (yte == 0)).sum())\n",
    "    fn = int(((yhat == 0) & (yte == 1)).sum())\n",
    "    acc = (tp + tn) / max(1, (tp + fp + tn + fn))\n",
    "    P, R, F1 = _prf(tp, fp, fn)\n",
    "    print(\n",
    "        f\"[{draw_name:7s}][Fold {fold_idx:02d}] WINNER TEST (image): acc={acc:.3f}  prec={P:.3f}  recall={R:.3f}  f1={F1:.3f}  \"\n",
    "        f\"[tp={tp} fp={fp} tn={tn} fn={fn}]\"\n",
    "    )\n",
    "\n",
    "    # package predictions per image with sid for subject voting\n",
    "    per_image = [\n",
    "        (sid, int(p), int(t)) for sid, p, t in zip(sid_te, yhat.tolist(), yte.tolist())\n",
    "    ]\n",
    "    return per_image, {\"tp\": tp, \"fp\": fp, \"tn\": tn, \"fn\": fn}\n",
    "\n",
    "\n",
    "# =========================\n",
    "# 5-fold driver (subject-wise) with WINNERS\n",
    "# =========================\n",
    "def _prf(tp: int, fp: int, fn: int):\n",
    "    prec = tp / (tp + fp) if (tp + fp) > 0 else 0.0\n",
    "    rec = tp / (tp + fn) if (tp + fn) > 0 else 0.0\n",
    "    f1 = (2 * prec * rec / (prec + rec)) if (prec + rec) > 0 else 0.0\n",
    "    return prec, rec, f1\n",
    "\n",
    "\n",
    "def run_subjectwise_5fold_winners(items_all, device, seed=42, feat_mode=FEAT_MODE):\n",
    "    sid2lab = subject_labels_from_items(items_all)\n",
    "    subjects = sorted(sid2lab.keys())\n",
    "    y_subject = np.array([sid2lab[s] for s in subjects], dtype=int)\n",
    "\n",
    "    skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=SEED % (2**32 - 1))\n",
    "\n",
    "    # ---------- MICRO accumulators (kept for reference/optional printing) ----------\n",
    "    per_draw_counts_global = {\n",
    "        d: {\"tp\": 0, \"fp\": 0, \"tn\": 0, \"fn\": 0} for d in DRAW_TYPES\n",
    "    }\n",
    "    per_draw_tp = {d: 0 for d in DRAW_TYPES}\n",
    "    per_draw_tot = {d: 0 for d in DRAW_TYPES}\n",
    "\n",
    "    subj_flat_counts_global = {\"tp\": 0, \"fp\": 0, \"tn\": 0, \"fn\": 0}\n",
    "    subj_flat_tp = subj_flat_tot = 0\n",
    "    subj_group_counts_global = {\"tp\": 0, \"fp\": 0, \"tn\": 0, \"fn\": 0}\n",
    "    subj_group_tp = subj_group_tot = 0\n",
    "\n",
    "    # ---------- MACRO accumulators ----------\n",
    "    per_draw_fold_accs = {d: [] for d in DRAW_TYPES}\n",
    "    subj_flat_macro_accs = []\n",
    "    subj_group_macro_accs = []\n",
    "\n",
    "    for fidx, (tr_idx, te_idx) in enumerate(skf.split(subjects, y_subject), 1):\n",
    "        print(\"\\n\" + \"#\" * 80)\n",
    "        print(\n",
    "            f\"############## SUBJECT-WISE CV — FOLD {fidx:02d} (WINNERS) ##############\"\n",
    "        )\n",
    "        print(\"#\" * 80 + \"\\n\")\n",
    "\n",
    "        train_sids = set(subjects[i] for i in tr_idx)\n",
    "        test_sids = set(subjects[i] for i in te_idx)\n",
    "        assert train_sids.isdisjoint(test_sids)\n",
    "\n",
    "        per_draw_items = {}\n",
    "        for d in DRAW_TYPES:\n",
    "            tr_items = [it for it in items_all if it[2] == d and it[3] in train_sids]\n",
    "            te_items = [it for it in items_all if it[2] == d and it[3] in test_sids]\n",
    "            per_draw_items[d] = (tr_items, te_items)\n",
    "\n",
    "        fold_preds_by_draw = {d: [] for d in DRAW_TYPES}  # (sid, pred, true)\n",
    "\n",
    "        # ----- Train/eval each draw with its fixed best classifier\n",
    "        for d in DRAW_TYPES:\n",
    "            tr_items, te_items = per_draw_items[d]\n",
    "            if len({lab for _fp, lab, _dr, _sid in tr_items}) < 2 or len(te_items) == 0:\n",
    "                print(\n",
    "                    f\"[{d:7s}][Fold {fidx:02d}] Skipped (class collapse or empty test).\"\n",
    "                )\n",
    "                continue\n",
    "\n",
    "            preds, counts = train_one_draw_and_eval(\n",
    "                tr_items, te_items, d, fidx, device, feat_mode=feat_mode\n",
    "            )\n",
    "            fold_preds_by_draw[d].extend(preds)\n",
    "\n",
    "            # ---- MICRO accumulation\n",
    "            per_draw_counts_global[d][\"tp\"] += counts[\"tp\"]\n",
    "            per_draw_counts_global[d][\"fp\"] += counts[\"fp\"]\n",
    "            per_draw_counts_global[d][\"tn\"] += counts[\"tn\"]\n",
    "            per_draw_counts_global[d][\"fn\"] += counts[\"fn\"]\n",
    "            per_draw_tp[d] += counts[\"tp\"] + counts[\"tn\"]\n",
    "            per_draw_tot[d] += counts[\"tp\"] + counts[\"tn\"] + counts[\"fp\"] + counts[\"fn\"]\n",
    "\n",
    "            # ---- MACRO: per-fold image accuracy for this draw\n",
    "            _tot = counts[\"tp\"] + counts[\"fp\"] + counts[\"tn\"] + counts[\"fn\"]\n",
    "            if _tot > 0:\n",
    "                per_draw_fold_accs[d].append((counts[\"tp\"] + counts[\"tn\"]) / _tot)\n",
    "\n",
    "        # ----- Subject-level voting (flat + group)\n",
    "        preds_by_sid_all = defaultdict(list)\n",
    "        preds_by_sid_by_draw = defaultdict(lambda: defaultdict(list))\n",
    "        for d in DRAW_TYPES:\n",
    "            for sid, pred, true in fold_preds_by_draw[d]:\n",
    "                preds_by_sid_all[sid].append(pred)\n",
    "                preds_by_sid_by_draw[sid][d].append(pred)\n",
    "\n",
    "        flat_tp = flat_fp = flat_tn = flat_fn = 0\n",
    "        group_tp = group_fp = group_tn = group_fn = 0\n",
    "\n",
    "        for sid in sorted(test_sids):\n",
    "            true_lab = sid2lab[sid]\n",
    "\n",
    "            # flat-majority across all images (all draws pooled)\n",
    "            if len(preds_by_sid_all[sid]) > 0:\n",
    "                z = preds_by_sid_all[sid].count(0)\n",
    "                o = len(preds_by_sid_all[sid]) - z\n",
    "                flat_pred = 1 if o > z else 0\n",
    "                subj_flat_tp += int(flat_pred == true_lab)  # MICRO bookkeeping\n",
    "                subj_flat_tot += 1\n",
    "                if flat_pred == 1 and true_lab == 1:\n",
    "                    flat_tp += 1\n",
    "                elif flat_pred == 1 and true_lab == 0:\n",
    "                    flat_fp += 1\n",
    "                elif flat_pred == 0 and true_lab == 0:\n",
    "                    flat_tn += 1\n",
    "                else:\n",
    "                    flat_fn += 1\n",
    "\n",
    "            # group-majority (majority inside each draw → majority across draws)\n",
    "            draw_votes = []\n",
    "            for d in DRAW_TYPES:\n",
    "                if len(preds_by_sid_by_draw[sid][d]) > 0:\n",
    "                    lst = preds_by_sid_by_draw[sid][d]\n",
    "                    zeros = lst.count(0)\n",
    "                    ones = len(lst) - zeros\n",
    "                    draw_votes.append(1 if ones > zeros else 0)\n",
    "            if len(draw_votes) > 0:\n",
    "                zeros = draw_votes.count(0)\n",
    "                ones = len(draw_votes) - zeros\n",
    "                group_pred = 1 if ones > zeros else 0\n",
    "                subj_group_tp += int(group_pred == true_lab)  # MICRO bookkeeping\n",
    "                subj_group_tot += 1\n",
    "                if group_pred == 1 and true_lab == 1:\n",
    "                    group_tp += 1\n",
    "                elif group_pred == 1 and true_lab == 0:\n",
    "                    group_fp += 1\n",
    "                elif group_pred == 0 and true_lab == 0:\n",
    "                    group_tn += 1\n",
    "                else:\n",
    "                    group_fn += 1\n",
    "\n",
    "        # ----- Per-fold subject-level report\n",
    "        P, R, F1 = _prf(flat_tp, flat_fp, flat_fn)\n",
    "        acc = (flat_tp + flat_tn) / max(1, (flat_tp + flat_fp + flat_tn + flat_fn))\n",
    "        print(\n",
    "            \"\\n--- SUBJECT-LEVEL (Flat) METRICS (Fold {:02d}) — WINNERS ---\".format(\n",
    "                fidx\n",
    "            )\n",
    "        )\n",
    "        print(\n",
    "            f\"acc={acc:.3f}  prec={P:.3f}  recall={R:.3f}  f1={F1:.3f}  \"\n",
    "            f\"[tp={flat_tp} fp={flat_fp} tn={flat_tn} fn={flat_fn}]\"\n",
    "        )\n",
    "\n",
    "        P, R, F1 = _prf(group_tp, group_fp, group_fn)\n",
    "        acc = (group_tp + group_tn) / max(\n",
    "            1, (group_tp + group_fp + group_tn + group_fn)\n",
    "        )\n",
    "        print(\n",
    "            \"\\n--- SUBJECT-LEVEL (Group) METRICS (Fold {:02d}) — WINNERS ---\".format(\n",
    "                fidx\n",
    "            )\n",
    "        )\n",
    "        print(\n",
    "            f\"acc={acc:.3f}  prec={P:.3f}  recall={R:.3f}  f1={F1:.3f}  \"\n",
    "            f\"[tp={group_tp} fp={group_fp} tn={group_tn} fn={group_fn}]\"\n",
    "        )\n",
    "\n",
    "        # ----- MACRO: record this fold's subject accuracies\n",
    "        flat_den = flat_tp + flat_fp + flat_tn + flat_fn\n",
    "        group_den = group_tp + group_fp + group_tn + group_fn\n",
    "        if flat_den > 0:\n",
    "            subj_flat_macro_accs.append((flat_tp + flat_tn) / flat_den)\n",
    "        if group_den > 0:\n",
    "            subj_group_macro_accs.append((group_tp + group_tn) / group_den)\n",
    "\n",
    "    # ================= FINAL REPORTS =================\n",
    "    # ---- PER-DRAW IMAGE ACCURACIES — MACRO\n",
    "    print(\"\\n=== PER-DRAW IMAGE ACCURACIES — WINNERS (MACRO over folds) ===\")\n",
    "    for d in DRAW_TYPES:\n",
    "        if per_draw_fold_accs[d]:\n",
    "            macro_acc = float(np.mean(per_draw_fold_accs[d]))\n",
    "            print(\n",
    "                f\"{d:8s}: macro_img_acc={macro_acc:.4f}  (from {len(per_draw_fold_accs[d])} folds)\"\n",
    "            )\n",
    "        else:\n",
    "            print(f\"{d:8s}: n/a (no valid folds)\")\n",
    "\n",
    "    # ---- PER-DRAW IMAGE ACCURACIES — MICRO (pooled)\n",
    "    print(\"\\n=== PER-DRAW IMAGE ACCURACIES — WINNERS (MICRO pooled) ===\")\n",
    "    for d in DRAW_TYPES:\n",
    "        if per_draw_tot[d] == 0:\n",
    "            print(f\"{d:8s}: n/a (no valid folds)\")\n",
    "        else:\n",
    "            print(\n",
    "                f\"{d:8s}: micro_img_acc={per_draw_tp[d]/per_draw_tot[d]:.4f}  [{per_draw_tp[d]}/{per_draw_tot[d]}]\"\n",
    "            )\n",
    "\n",
    "    # ---- PER-DRAW IMAGE PRF — MICRO (pooled)\n",
    "    print(\"\\n=== PER-DRAW IMAGE PRF — WINNERS (MICRO pooled) ===\")\n",
    "    for d in DRAW_TYPES:\n",
    "        c = per_draw_counts_global[d]\n",
    "        if sum(c.values()) == 0:\n",
    "            print(f\"{d:8s}: n/a\")\n",
    "            continue\n",
    "        P, R, F1 = _prf(c[\"tp\"], c[\"fp\"], c[\"fn\"])\n",
    "        acc = (c[\"tp\"] + c[\"tn\"]) / max(1, (c[\"tp\"] + c[\"fp\"] + c[\"tn\"] + c[\"fn\"]))\n",
    "        print(\n",
    "            f\"{d:8s}: acc={acc:.3f}  prec={P:.3f}  recall={R:.3f}  f1={F1:.3f}  \"\n",
    "            f\"[tp={c['tp']} fp={c['fp']} tn={c['tn']} fn={c['fn']}]\"\n",
    "        )\n",
    "\n",
    "    # ---- SUBJECT-LEVEL ACCURACIES — MACRO\n",
    "    print(\"\\n=== SUBJECT-LEVEL ACCURACIES — WINNERS (MACRO over folds) ===\")\n",
    "    if subj_flat_macro_accs:\n",
    "        flat_macro = float(np.mean(subj_flat_macro_accs))\n",
    "        print(f\"Flat-majority (macro):   {flat_macro:.4f}\")\n",
    "    else:\n",
    "        print(\"Flat-majority (macro):   n/a\")\n",
    "    if subj_group_macro_accs:\n",
    "        group_macro = float(np.mean(subj_group_macro_accs))\n",
    "        print(f\"Group-majority (macro):  {group_macro:.4f}\")\n",
    "    else:\n",
    "        print(\"Group-majority (macro):  n/a\")\n",
    "\n",
    "    # ---- SUBJECT-LEVEL ACCURACIES — MICRO (pooled)\n",
    "    flat_acc = subj_flat_tp / max(1, subj_flat_tot)\n",
    "    group_acc = subj_group_tp / max(1, subj_group_tot)\n",
    "    print(\"\\n=== SUBJECT-LEVEL ACCURACIES — WINNERS (MICRO pooled) ===\")\n",
    "    print(f\"Flat-majority (micro):   {flat_acc:.4f}  [{subj_flat_tp}/{subj_flat_tot}]\")\n",
    "    print(\n",
    "        f\"Group-majority (micro):  {group_acc:.4f}  [{subj_group_tp}/{subj_group_tot}]\"\n",
    "    )\n",
    "\n",
    "    # ---- SUBJECT-LEVEL PRF — MICRO\n",
    "    print(\"\\n=== SUBJECT-LEVEL PRF — WINNERS (MICRO pooled) ===\")\n",
    "    c = subj_flat_counts_global\n",
    "    P, R, F1 = _prf(c[\"tp\"], c[\"fp\"], c[\"fn\"])\n",
    "    acc = (c[\"tp\"] + c[\"tn\"]) / max(1, (c[\"tp\"] + c[\"fp\"] + c[\"tn\"] + c[\"fn\"]))\n",
    "    print(\n",
    "        f\"Flat-majority:  acc={acc:.3f}  prec={P:.3f}  recall={R:.3f}  f1={F1:.3f}  \"\n",
    "        f\"[tp={c['tp']} fp={c['fp']} tn={c['tn']} fn={c['fn']}]\"\n",
    "    )\n",
    "\n",
    "    c = subj_group_counts_global\n",
    "    P, R, F1 = _prf(c[\"tp\"], c[\"fp\"], c[\"fn\"])\n",
    "    acc = (c[\"tp\"] + c[\"tn\"]) / max(1, (c[\"tp\"] + c[\"fp\"] + c[\"tn\"] + c[\"fn\"]))\n",
    "    print(\n",
    "        f\"Group-majority: acc={acc:.3f}  prec={P:.3f}  recall={R:.3f}  f1={F1:.3f}  \"\n",
    "        f\"[tp={c['tp']} fp={c['fp']} tn={c['tn']} fn={c['fn']}]\"\n",
    "    )\n",
    "\n",
    "\n",
    "# =========================\n",
    "# Kickoff\n",
    "# =========================\n",
    "if __name__ == \"__main__\":\n",
    "    OUTDIR.mkdir(parents=True, exist_ok=True)\n",
    "    items_all = discover_items_tree(DATA_ROOT)\n",
    "    results = run_subjectwise_5fold_winners(\n",
    "        items_all, device, seed=SEED, feat_mode=FEAT_MODE\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
